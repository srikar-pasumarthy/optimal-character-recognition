{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists datasets available from tensorflow_datasets\n",
    "#tfds.list_builders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load emnist dataset from tf\n",
    "#(ds_train, ds_test), ds_info = tfds.load(\n",
    "#    \"mnist\",\n",
    "#    split=[\"train\", \"test\"],\n",
    "#    shuffle_files=True,\n",
    "#    as_supervised=True,\n",
    "#    with_info=True,\n",
    "#)\n",
    "\n",
    "ds_train = pd.read_csv('emnist-byclass-train.csv')\n",
    "ds_test = pd.read_csv('emnist-byclass-test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (697931, 785)\n",
      "Testing shape: (116322, 785)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training shape: \" + str(ds_train.shape))\n",
    "print(\"Testing shape: \" + str(ds_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(697931, 784)\n",
      "(697931,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(ds_train))\n",
    "train_images = np.array(ds_train.iloc[:,1:])\n",
    "train_labels = np.array(ds_train.iloc[:,0])\n",
    "\n",
    "test_images = np.array(ds_test.iloc[:,1:])\n",
    "test_labels = np.array(ds_test.iloc[:,0])\n",
    "\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "#print(train_labels.iloc[[0, 1, 2, 3, 4, 5]])\n",
    "print(type(train_images))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing of data here\n",
    "#def normalize_img(image, label):\n",
    "#    \"\"\"Converts image from uint8 to float32 and normalizes\"\"\"\n",
    "#    return tf.cast(image, tf.float32) / 255.0, label\n",
    "\n",
    "#AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "#BATCH_SIZE = 64\n",
    "\n",
    "#train_images = train_images.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "# Some other pre-proc steps that are supposed to help\n",
    "#train_images = train_images.cache()\n",
    "#train_images = train_images.shuffle(1000)\n",
    "#train_images = train_images.batch(BATCH_SIZE)\n",
    "#train_images = train_images.prefetch(AUTOTUNE)\n",
    "\n",
    "#ds_test = ds_test.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
    "#ds_test = ds_test.batch(BATCH_SIZE)\n",
    "#ds_test = ds_test.prefetch(AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.004 0.075 0.106 0.031 0.    0.\n",
      "  0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.031 0.184 0.616 0.741 0.494 0.129 0.004\n",
      "  0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.031 0.129 0.494 0.816 0.969 0.988 0.957 0.624 0.086\n",
      "  0.012 0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.012 0.141 0.357 0.812 0.961 0.98  0.984 0.988 0.812 0.18\n",
      "  0.031 0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.012 0.263 0.686 0.867 0.988 0.867 0.561 0.561 0.875 0.957 0.447\n",
      "  0.125 0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.02\n",
      "  0.075 0.204 0.686 0.976 0.965 0.812 0.357 0.047 0.075 0.604 0.949 0.447\n",
      "  0.125 0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.012 0.184\n",
      "  0.478 0.859 0.969 0.906 0.686 0.188 0.027 0.035 0.18  0.816 0.859 0.196\n",
      "  0.035 0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.078 0.392\n",
      "  0.686 0.973 0.965 0.765 0.482 0.047 0.    0.082 0.322 0.906 0.8   0.133\n",
      "  0.016 0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.047 0.482 0.906\n",
      "  0.969 0.957 0.643 0.184 0.078 0.    0.    0.149 0.498 0.961 0.545 0.035\n",
      "  0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.012 0.078 0.482 0.871 0.984\n",
      "  0.918 0.514 0.129 0.004 0.    0.    0.008 0.322 0.675 0.898 0.322 0.008\n",
      "  0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.004 0.141 0.373 0.906 0.988 0.859\n",
      "  0.624 0.09  0.    0.    0.    0.    0.086 0.561 0.855 0.671 0.086 0.\n",
      "  0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.086 0.624 0.859 0.988 0.859 0.357\n",
      "  0.137 0.004 0.    0.    0.    0.047 0.482 0.898 0.886 0.325 0.012 0.\n",
      "  0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.004 0.184 0.812 0.957 0.965 0.639 0.137\n",
      "  0.035 0.    0.    0.004 0.027 0.188 0.686 0.949 0.82  0.18  0.    0.\n",
      "  0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.086 0.624 0.965 0.976 0.686 0.141 0.004\n",
      "  0.    0.008 0.035 0.184 0.373 0.812 0.969 0.937 0.745 0.161 0.004 0.\n",
      "  0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.008 0.322 0.906 0.918 0.733 0.263 0.012 0.004\n",
      "  0.031 0.302 0.545 0.82  0.91  0.992 0.996 0.992 0.965 0.639 0.129 0.\n",
      "  0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.035 0.545 0.953 0.624 0.314 0.02  0.075 0.204\n",
      "  0.376 0.855 0.98  0.996 0.992 0.918 0.855 0.871 0.925 0.953 0.494 0.031\n",
      "  0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.016 0.125 0.796 0.867 0.204 0.047 0.047 0.478 0.859\n",
      "  0.918 0.992 0.996 0.965 0.859 0.376 0.153 0.251 0.518 0.953 0.8   0.133\n",
      "  0.016 0.    0.    0.   ]\n",
      " [0.    0.    0.    0.016 0.145 0.843 0.851 0.157 0.047 0.188 0.686 0.973\n",
      "  0.988 1.    0.992 0.859 0.639 0.141 0.02  0.094 0.314 0.863 0.859 0.196\n",
      "  0.035 0.    0.    0.   ]\n",
      " [0.    0.    0.    0.016 0.145 0.843 0.871 0.329 0.388 0.812 0.969 0.996\n",
      "  0.996 0.98  0.855 0.357 0.137 0.004 0.    0.004 0.043 0.553 0.929 0.4\n",
      "  0.11  0.    0.    0.   ]\n",
      " [0.    0.    0.    0.008 0.078 0.62  0.933 0.89  0.918 0.992 0.996 0.957\n",
      "  0.863 0.545 0.302 0.031 0.004 0.    0.    0.    0.016 0.447 0.898 0.373\n",
      "  0.102 0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.004 0.129 0.494 0.796 0.843 0.851 0.8   0.494\n",
      "  0.31  0.043 0.008 0.    0.    0.    0.    0.    0.    0.196 0.831 0.439\n",
      "  0.125 0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.027 0.18  0.447 0.49  0.498 0.447 0.18\n",
      "  0.086 0.004 0.    0.    0.    0.    0.    0.    0.    0.153 0.769 0.322\n",
      "  0.082 0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.016 0.016 0.016 0.016 0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.122 0.6   0.129\n",
      "  0.016 0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.02  0.102 0.02\n",
      "  0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.   ]]\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (28,28) into shape (784,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39mreshape(train_images[i], (\u001b[39m28\u001b[39m, \u001b[39m28\u001b[39m)))\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m()\n\u001b[0;32m----> 9\u001b[0m train_images[i] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(train_images[i], (\u001b[39m28\u001b[39m, \u001b[39m28\u001b[39m))\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(train_images[i])\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m()\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (28,28) into shape (784,)"
     ]
    }
   ],
   "source": [
    "# See some info about the dataset\n",
    "# There should be more samples, need to look into this\n",
    "#print(train_images[0])\n",
    "i: int = 0\n",
    "\n",
    "while (i < 3):\n",
    "    print(np.reshape(train_images[i], (28, 28)))\n",
    "    print()\n",
    "    train_images[i] = np.reshape(train_images[i], (28, 28))\n",
    "    print(train_images[i])\n",
    "    print()\n",
    "    print()\n",
    "    i = i+1\n",
    "\n",
    "print(train_images[0].shape)\n",
    "print()\n",
    "#print(train_images[0])\n",
    "#print(train_images[0])\n",
    "print(len(train_images))\n",
    "print(len(test_images))\n",
    "print(len(train_images) + len(test_images))\n",
    "#print(ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the model structure\n",
    "model = tf.keras.Sequential([\n",
    "    #tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.InputLayer(input_shape=784),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    #tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(62)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39mfit(x\u001b[39m=\u001b[39mtrain_images, y\u001b[39m=\u001b[39mtrain_labels, epochs\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(x=train_images, y=train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3636/3636 - 5s - loss: 0.5410 - accuracy: 0.8316 - 5s/epoch - 1ms/step\n",
      "\n",
      "Test Accuracy:  0.8316397666931152\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x=test_images, y=test_labels, verbose=2)\n",
    "\n",
    "print('\\nTest Accuracy: ', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0c5f31dd2b59b9051abbbc4a81d3935c5008b7ae2cf271c91b90993ceb3332b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
